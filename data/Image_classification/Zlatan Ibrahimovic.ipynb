{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2d73972-f0b2-4332-8f81-876d95fe39ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import cv2\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f79edf-a7c0-4d85-9455-1a0577d5a686",
   "metadata": {},
   "source": [
    "## Class: PlayerVerificationSystem\n",
    "\n",
    "This class verifies the identity of a football player by comparing an official image from Flashscore with user-provided selfies.\n",
    "\n",
    "---\n",
    "\n",
    "## `__init__(self)`\n",
    "\n",
    "- Initializes the face recognition model (`buffalo_l` from InsightFace).\n",
    "- Prepares the model to work on CPU.\n",
    "- Sets a default similarity threshold of `0.68` for verification.\n",
    "\n",
    "---\n",
    "\n",
    "## `search_player_profile(self, player_name: str) -> Optional[str]`\n",
    "\n",
    "- Searches for the player's Flashscore profile using DuckDuckGo search.\n",
    "- Returns the URL of the profile if found, otherwise `None`.\n",
    "\n",
    "---\n",
    "\n",
    "## `extract_player_image(self, profile_url: str, player_name: str) -> Optional[str]`\n",
    "\n",
    "- Fetches the player's Flashscore profile page.\n",
    "- Extracts the player's official image URL by matching `alt` text or keywords.\n",
    "- Returns the image URL if successful, otherwise `None`.\n",
    "\n",
    "---\n",
    "\n",
    "## `process_image(self, image_path: str, is_url: bool = False) -> Optional[np.ndarray]`\n",
    "\n",
    "- Loads an image either from a local path or a URL.\n",
    "- Returns the loaded image as a NumPy array.\n",
    "- Returns `None` if loading fails.\n",
    "\n",
    "---\n",
    "\n",
    "## `get_face_embedding(self, image: np.ndarray) -> Optional[np.ndarray]`\n",
    "\n",
    "- Detects the face in the image using the prepared model.\n",
    "- Extracts the normalized face embedding vector.\n",
    "- Returns the embedding or `None` if no face is found.\n",
    "\n",
    "---\n",
    "\n",
    "## `verify_player_identity(self, player_name: str, selfie_paths: List[str], save_log: bool = False) -> Dict`\n",
    "\n",
    "**Workflow:**\n",
    "1. Search for the player profile.\n",
    "2. Extract the official image.\n",
    "3. Process the official image and extract its embedding.\n",
    "4. Process the provided selfies and extract their embeddings.\n",
    "5. Average the selfies' embeddings.\n",
    "6. Compute cosine similarity between the official and combined selfie embeddings.\n",
    "7. Decide if the player is verified based on the threshold.\n",
    "8. Optionally save the verification result in a log file.\n",
    "\n",
    "**Returns:**  \n",
    "A dictionary containing success status, similarity score, verification result, official image URL, and number of selfies used.\n",
    "\n",
    "---\n",
    "\n",
    "## `_save_verification_log(self, player_name: str, similarity_score: float, is_verified: bool) -> None`\n",
    "\n",
    "- Saves the verification result (timestamp, player, similarity score, verification decision) into `verification_logs.json`.\n",
    "- If the file does not exist, it creates one.\n",
    "- Appends each new verification result.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb447be7-e010-43a7-8f1b-f30c3f3f8372",
   "metadata": {},
   "source": [
    "# Initialize the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1deecf83-6a9f-4c58-94d1-1905c5c73bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerVerificationSystem:\n",
    "    def __init__(self):\n",
    "        # Initialize face analysis model (ArcFace)\n",
    "        self.face_model = FaceAnalysis(name=\"buffalo_l\", providers=[\"CPUExecutionProvider\"])\n",
    "        self.face_model.prepare(ctx_id=0, det_size=(640, 640))\n",
    "        self.similarity_threshold = 0.68  # Can be adjusted based on testing\n",
    "\n",
    "    def search_player_profile(self, player_name: str) -> Optional[str]:\n",
    "        \"\"\"Search for player profile on Flashscore using DuckDuckGo\"\"\"\n",
    "        query = f\"{player_name} site:flashscore.com/player\"\n",
    "        url = \"https://html.duckduckgo.com/html/\"\n",
    "        \n",
    "        params = {\"q\": query}\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "        try:\n",
    "            response = requests.post(url, data=params, headers=headers, timeout=10)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            \n",
    "            for link in soup.find_all(\"a\", href=True):\n",
    "                href = link[\"href\"]\n",
    "                if \"flashscore.com/player\" in href:\n",
    "                    return href\n",
    "        except Exception as e:\n",
    "            print(f\"Search error: {str(e)}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def extract_player_image(self, profile_url: str, player_name: str) -> Optional[str]:\n",
    "        \"\"\"Extract official player image from Flashscore profile\"\"\"\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        \n",
    "        try:\n",
    "            res = requests.get(profile_url, headers=headers, timeout=10)\n",
    "            soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "            \n",
    "            # Search for player image\n",
    "            search_parts = player_name.lower().split()\n",
    "            for img in soup.find_all(\"img\"):\n",
    "                src = img.get(\"src\", \"\")\n",
    "                alt = img.get(\"alt\", \"\").lower()\n",
    "                \n",
    "                if any(part in alt for part in search_parts) or \"player\" in alt:\n",
    "                    if src.startswith(\"//\"):\n",
    "                        return f\"https:{src}\"\n",
    "                    elif src.startswith(\"http\"):\n",
    "                        return src\n",
    "        except Exception as e:\n",
    "            print(f\"Image extraction error: {str(e)}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def process_image(self, image_path: str, is_url: bool = False) -> Optional[np.ndarray]:\n",
    "        \"\"\"Load and process image from path or URL\"\"\"\n",
    "        try:\n",
    "            if is_url:\n",
    "                headers = {\n",
    "                    \"User-Agent\": \"Mozilla/5.0\",\n",
    "                    \"Referer\": \"https://www.flashscore.com/\"\n",
    "                }\n",
    "                resp = requests.get(image_path, headers=headers, timeout=10)\n",
    "                arr = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "                img = cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
    "            else:\n",
    "                img = cv2.imread(image_path)\n",
    "            \n",
    "            return img\n",
    "        except Exception as e:\n",
    "            print(f\"Image processing error: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def get_face_embedding(self, image: np.ndarray) -> Optional[np.ndarray]:\n",
    "        \"\"\"Extract face embedding from image\"\"\"\n",
    "        try:\n",
    "            faces = self.face_model.get(image)\n",
    "            if faces:\n",
    "                return faces[0].embedding\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Face detection error: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def verify_player_identity(\n",
    "        self,\n",
    "        player_name: str,\n",
    "        selfie_paths: List[str],\n",
    "        save_log: bool = False\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Main verification workflow:\n",
    "        1. Search for player profile\n",
    "        2. Extract official image\n",
    "        3. Process selfies and official image\n",
    "        4. Compare embeddings\n",
    "        5. Return verification result\n",
    "        \"\"\"\n",
    "        # 1. Find player profile\n",
    "        profile_url = self.search_player_profile(player_name)\n",
    "        if not profile_url:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"reason\": \"Player profile not found\",\n",
    "                \"player\": player_name,\n",
    "                \"verified\": False,\n",
    "                \"similarity_score\": 0.0\n",
    "            }\n",
    "        \n",
    "        # 2. Extract official image\n",
    "        official_img_url = self.extract_player_image(profile_url, player_name)\n",
    "        if not official_img_url:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"reason\": \"Official image not found\",\n",
    "                \"player\": player_name,\n",
    "                \"verified\": False,\n",
    "                \"similarity_score\": 0.0\n",
    "            }\n",
    "        \n",
    "        # 3. Process official image\n",
    "        official_img = self.process_image(official_img_url, is_url=True)\n",
    "        if official_img is None:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"reason\": \"Failed to process official image\",\n",
    "                \"player\": player_name,\n",
    "                \"verified\": False,\n",
    "                \"similarity_score\": 0.0\n",
    "            }\n",
    "        \n",
    "        official_embedding = self.get_face_embedding(official_img)\n",
    "        if official_embedding is None:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"reason\": \"No face detected in official image\",\n",
    "                \"player\": player_name,\n",
    "                \"verified\": False,\n",
    "                \"similarity_score\": 0.0\n",
    "            }\n",
    "        \n",
    "        # 4. Process and combine selfies\n",
    "        valid_selfie_embeddings = []\n",
    "        for path in selfie_paths:\n",
    "            selfie_img = self.process_image(path)\n",
    "            if selfie_img is None:\n",
    "                continue\n",
    "                \n",
    "            selfie_embedding = self.get_face_embedding(selfie_img)\n",
    "            if selfie_embedding is not None:\n",
    "                valid_selfie_embeddings.append(selfie_embedding)\n",
    "        \n",
    "        if len(valid_selfie_embeddings) < 1:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"reason\": \"No valid selfies provided\",\n",
    "                \"player\": player_name,\n",
    "                \"verified\": False,\n",
    "                \"similarity_score\": 0.0\n",
    "            }\n",
    "        \n",
    "        # Average all selfie embeddings\n",
    "        combined_embedding = np.mean(valid_selfie_embeddings, axis=0)\n",
    "        \n",
    "        # 5. Calculate similarity\n",
    "        similarity_score = cosine_similarity(\n",
    "            official_embedding.reshape(1, -1),\n",
    "            combined_embedding.reshape(1, -1))\n",
    "        similarity_score = float(similarity_score[0][0])\n",
    "        \n",
    "        is_verified = similarity_score >= self.similarity_threshold\n",
    "        \n",
    "        # Save verification log if requested\n",
    "        if save_log:\n",
    "            self._save_verification_log(\n",
    "                player_name,\n",
    "                similarity_score,\n",
    "                is_verified\n",
    "            )\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"player\": player_name,\n",
    "            \"verified\": is_verified,\n",
    "            \"similarity_score\": similarity_score,\n",
    "            \"official_image_url\": official_img_url,\n",
    "            \"selfies_used\": len(valid_selfie_embeddings),\n",
    "            \"threshold\": self.similarity_threshold\n",
    "        }\n",
    "    \n",
    "    def _save_verification_log(\n",
    "        self,\n",
    "        player_name: str,\n",
    "        similarity_score: float,\n",
    "        is_verified: bool\n",
    "    ) -> None:\n",
    "        \"\"\"Save verification log to file\"\"\"\n",
    "        log_entry = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"player\": player_name,\n",
    "            \"similarity_score\": similarity_score,\n",
    "            \"verified\": is_verified,\n",
    "            \"threshold\": self.similarity_threshold\n",
    "        }\n",
    "        \n",
    "        log_file = \"verification_logs.json\"\n",
    "        \n",
    "        # Create file if it doesn't exist\n",
    "        if not os.path.exists(log_file):\n",
    "            with open(log_file, \"w\") as f:\n",
    "                f.write(\"[]\")\n",
    "        \n",
    "        # Append new log entry\n",
    "        try:\n",
    "            with open(log_file, \"r+\") as f:\n",
    "                logs = json.load(f)\n",
    "                logs.append(log_entry)\n",
    "                f.seek(0)\n",
    "                json.dump(logs, f, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save log: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "282e8451-e087-4f74-afd9-2d676d102348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\bouaz/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\bouaz/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\bouaz/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\bouaz/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\bouaz/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "verifier = PlayerVerificationSystem()\n",
    "# Initialize empty results list\n",
    "sample_results = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a180442a-5c15-41da-a598-c0bf68189c6c",
   "metadata": {},
   "source": [
    "# Autogenerated verification script for player identity evaluation\n",
    " Note: File paths are assumed to match player2 last names as shown in the directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "163b2aa8-7746-4fd9-861c-5931ed0d436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all results\n",
    "for res in sample_results:\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5ac4e5a-2a90-493d-8259-9e43070f47b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': False, 'reason': 'Player profile not found', 'player': 'Benjamin Sesko', 'verified': False, 'similarity_score': 0.0}\n",
      "{'success': False, 'reason': 'Player profile not found', 'player': 'Jonathan Clauss', 'verified': False, 'similarity_score': 0.0}\n",
      "{'success': False, 'reason': 'Player profile not found', 'player': 'Gonçalo Inácio', 'verified': False, 'similarity_score': 0.0}\n",
      "{'success': False, 'reason': 'Player profile not found', 'player': 'Zeki Celik', 'verified': False, 'similarity_score': 0.0}\n",
      "{'success': False, 'reason': 'Player profile not found', 'player': 'Cody Gakpo', 'verified': False, 'similarity_score': 0.0}\n",
      "{'success': False, 'reason': 'Player profile not found', 'player': 'Donyell Malen', 'verified': False, 'similarity_score': 0.0}\n",
      "{'success': False, 'reason': 'Player profile not found', 'player': 'Luca Netz', 'verified': False, 'similarity_score': 0.0}\n",
      "{'success': False, 'reason': 'Player profile not found', 'player': 'Josip Stanisic', 'verified': False, 'similarity_score': 0.0}\n"
     ]
    }
   ],
   "source": [
    "sample_results = []\n",
    "\n",
    "# Verify Benjamin Sesko\n",
    "result = verifier.verify_player_identity(\n",
    "    \"Benjamin Sesko\",\n",
    "    [\n",
    "        \"C:/Users/bouaz/Downloads/Patrick Schick1.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Patrick Schick2.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Patrick Schick3.jpg\",\n",
    "    ],\n",
    "    save_log=True\n",
    ")\n",
    "sample_results.append({\n",
    "    \"player\": \"Benjamin Sesko\",\n",
    "    \"similarity\": result[\"similarity_score\"],\n",
    "    \"verified\": result[\"verified\"],\n",
    "    \"ground_truth\": False\n",
    "})\n",
    "print(result)\n",
    "\n",
    "# Verify Jonathan Clauss\n",
    "result = verifier.verify_player_identity(\n",
    "    \"Jonathan Clauss\",\n",
    "    [\n",
    "        \"C:/Users/bouaz/Downloads/Thomas Meunier1.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Thomas Meunier1.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Thomas Meunier1.jpg\",\n",
    "    ],\n",
    "    save_log=True\n",
    ")\n",
    "sample_results.append({\n",
    "    \"player\": \"Jonathan Clauss\",\n",
    "    \"similarity\": result[\"similarity_score\"],\n",
    "    \"verified\": result[\"verified\"],\n",
    "    \"ground_truth\": False\n",
    "})\n",
    "print(result)\n",
    "\n",
    "# Verify Gonçalo Inácio\n",
    "result = verifier.verify_player_identity(\n",
    "    \"Gonçalo Inácio\",\n",
    "    [\n",
    "        \"C:/Users/bouaz/Downloads/Djalo.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Djalo1.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Djalo2.jpg\",\n",
    "    ],\n",
    "    save_log=True\n",
    ")\n",
    "sample_results.append({\n",
    "    \"player\": \"Gonçalo Inácio\",\n",
    "    \"similarity\": result[\"similarity_score\"],\n",
    "    \"verified\": result[\"verified\"],\n",
    "    \"ground_truth\": False\n",
    "})\n",
    "print(result)\n",
    "\n",
    "# Verify Zeki Celik\n",
    "result = verifier.verify_player_identity(\n",
    "    \"Zeki Celik\",\n",
    "    [\n",
    "        \"C:/Users/bouaz/Downloads/Soyuncu.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Soyuncu1.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Soyuncu2.jpg\",\n",
    "    ],\n",
    "    save_log=True\n",
    ")\n",
    "sample_results.append({\n",
    "    \"player\": \"Zeki Celik\",\n",
    "    \"similarity\": result[\"similarity_score\"],\n",
    "    \"verified\": result[\"verified\"],\n",
    "    \"ground_truth\": False\n",
    "})\n",
    "print(result)\n",
    "\n",
    "# Verify Cody Gakpo\n",
    "result = verifier.verify_player_identity(\n",
    "    \"Cody Gakpo\",\n",
    "    [\n",
    "        \"C:/Users/bouaz/Downloads/Mateta.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Mateta1.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Mateta2.jpg\",\n",
    "    ],\n",
    "    save_log=True\n",
    ")\n",
    "sample_results.append({\n",
    "    \"player\": \"Cody Gakpo\",\n",
    "    \"similarity\": result[\"similarity_score\"],\n",
    "    \"verified\": result[\"verified\"],\n",
    "    \"ground_truth\": False\n",
    "})\n",
    "print(result)\n",
    "\n",
    "# Verify Donyell Malen\n",
    "result = verifier.verify_player_identity(\n",
    "    \"Donyell Malen\",\n",
    "    [\n",
    "        \"C:/Users/bouaz/Downloads/Boadu.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Boadu1.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Boadu2.jpg\",\n",
    "    ],\n",
    "    save_log=True\n",
    ")\n",
    "sample_results.append({\n",
    "    \"player\": \"Donyell Malen\",\n",
    "    \"similarity\": result[\"similarity_score\"],\n",
    "    \"verified\": result[\"verified\"],\n",
    "    \"ground_truth\": False\n",
    "})\n",
    "print(result)\n",
    "\n",
    "# Verify Luca Netz\n",
    "result = verifier.verify_player_identity(\n",
    "    \"Luca Netz\",\n",
    "    [\n",
    "        \"C:/Users/bouaz/Downloads/Raum.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Raum1.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Raum2.jpg\",\n",
    "    ],\n",
    "    save_log=True\n",
    ")\n",
    "sample_results.append({\n",
    "    \"player\": \"Luca Netz\",\n",
    "    \"similarity\": result[\"similarity_score\"],\n",
    "    \"verified\": result[\"verified\"],\n",
    "    \"ground_truth\": False\n",
    "})\n",
    "print(result)\n",
    "\n",
    "# Verify Josip Stanisic\n",
    "result = verifier.verify_player_identity(\n",
    "    \"Josip Stanisic\",\n",
    "    [\n",
    "        \"C:/Users/bouaz/Downloads/Sosa.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Sosa1.jpg\",\n",
    "        \"C:/Users/bouaz/Downloads/Sosa2.jpg\",\n",
    "    ],\n",
    "    save_log=True\n",
    ")\n",
    "sample_results.append({\n",
    "    \"player\": \"Josip Stanisic\",\n",
    "    \"similarity\": result[\"similarity_score\"],\n",
    "    \"verified\": result[\"verified\"],\n",
    "    \"ground_truth\": False\n",
    "})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3befbe-84b4-4483-a18c-a50c8768283a",
   "metadata": {},
   "source": [
    "#  Save combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00cfa395-177e-4b9d-8005-98bf73f33d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Appended results to existing file at C:\\Users\\bouaz\\Downloads\\verification_results1.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Suppose your results are in this list\n",
    "# sample_results = [...]  # your list of dicts\n",
    "\n",
    "# 1. Get the Downloads folder\n",
    "downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "\n",
    "# 2. Define the output file path\n",
    "csv_output_file = os.path.join(downloads_folder, \"verification_results1.csv\")\n",
    "\n",
    "# 3. Create the DataFrame from current session\n",
    "df_new = pd.DataFrame(sample_results)\n",
    "\n",
    "# 4. Check if the file already exists\n",
    "if os.path.exists(csv_output_file):\n",
    "    # 4.a If file exists, load existing data\n",
    "    df_existing = pd.read_csv(csv_output_file)\n",
    "\n",
    "    # 4.b Append new data to existing\n",
    "    df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "\n",
    "    # 4.c Save combined data\n",
    "    df_combined.to_csv(csv_output_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ Appended results to existing file at {csv_output_file}\")\n",
    "\n",
    "else:\n",
    "    # 4.d If file doesn't exist, create it\n",
    "    df_new.to_csv(csv_output_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ Created new results file at {csv_output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cf4c6fb-d4ad-4965-8924-bcbe9bae2561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bouaz\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 2. Generate the metrics dashboard\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m metrics_fig \u001b[38;5;241m=\u001b[39m generate_metrics_report(sample_results)\n\u001b[0;32m      3\u001b[0m metrics_fig\u001b[38;5;241m.\u001b[39mshow()  \u001b[38;5;66;03m# Display in notebook or save with savefig()\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 3. Create face comparison visualization (using sample images)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load sample images - replace with your actual image paths\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 13\u001b[0m, in \u001b[0;36mgenerate_metrics_report\u001b[1;34m(verification_results)\u001b[0m\n\u001b[0;32m     10\u001b[0m y_true \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m verification_results]\n\u001b[0;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.68\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m verification_results]\n\u001b[1;32m---> 13\u001b[0m tn, fp, fn, tp \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true, y_pred)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m     14\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m (tp \u001b[38;5;241m+\u001b[39m tn) \u001b[38;5;241m/\u001b[39m (tp \u001b[38;5;241m+\u001b[39m tn \u001b[38;5;241m+\u001b[39m fp \u001b[38;5;241m+\u001b[39m fn)\n\u001b[0;32m     15\u001b[0m precision \u001b[38;5;241m=\u001b[39m tp \u001b[38;5;241m/\u001b[39m (tp \u001b[38;5;241m+\u001b[39m fp)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 2. Generate the metrics dashboard\n",
    "metrics_fig = generate_metrics_report(sample_results)\n",
    "metrics_fig.show()  # Display in notebook or save with savefig()\n",
    "\n",
    "# 3. Create face comparison visualization (using sample images)\n",
    "# Load sample images - replace with your actual image paths\n",
    "player_img = cv2.imread(\"official_zlatan.png\")\n",
    "selfie1 = cv2.imread( \"C:/Users/bouaz/Downloads/download (3).jpg\")\n",
    "selfie2 = cv2.imread( \"C:/Users/bouaz/Downloads/download (5).jpg\")\n",
    "selfie3 = cv2.imread( \"C:/Users/bouaz/Downloads/download (2).jpg\")\n",
    "\n",
    "create_face_comparison_grid(\n",
    "    player_img=player_img,\n",
    "    selfies=[selfie1, selfie2, selfie3],\n",
    "    similarities=[0.72, 0.68, 0.75]\n",
    ")\n",
    "\n",
    "# 4. Run performance benchmarking\n",
    "test_cases = [\n",
    "    {\n",
    "        \"player_name\": \"Zlatan Ibrahimovic\",\n",
    "        \"selfie_paths\": [\"C:/Users/bouaz/Downloads/download (2).jpg\", \"C:/Users/bouaz/Downloads/download (5).jpg\", \"C:/Users/bouaz/Downloads/download (2)\"],\n",
    "        \"img_width\": 640,\n",
    "        \"img_height\": 480\n",
    "    },\n",
    "    {\n",
    "        \"player_name\": \"Lionel Messi\",\n",
    "        \"selfie_paths\": [\"C:/Users/bouaz/Downloads/messi1.jpg\",\"C:/Users/bouaz/Downloads/messi2.jpg\",\"C:/Users/bouaz/Downloads/messi3.jpg\"],\n",
    "        \"img_width\": 1280,\n",
    "        \"img_height\": 720\n",
    "    }\n",
    "]\n",
    "\n",
    "benchmark_df = benchmark_system(test_cases)\n",
    "print(benchmark_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4272dacd-2ed6-4d9c-b523-4a6d511a3eea",
   "metadata": {},
   "source": [
    "## FastAPI Server for Player Verification\n",
    "\n",
    "This FastAPI server exposes two endpoints:\n",
    "- `/verify_player`: Verify a player's identity based on uploaded selfies.\n",
    "- `/verification_logs`: Retrieve previous verification logs.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Initialize FastAPI App\n",
    "\n",
    "- Creates a new FastAPI application instance.\n",
    "- Instantiates the `PlayerVerificationSystem` to handle the verification logic.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Class: `VerificationRequest`\n",
    "\n",
    "- Defines a Pydantic model with:\n",
    "  - `player_name`: the name of the player to verify.\n",
    "- Used to validate the request body for the `/verify_player` endpoint.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. POST `/verify_player`\n",
    "\n",
    "**Endpoint to verify player identity using three uploaded selfies.**\n",
    "\n",
    "### Workflow:\n",
    "1. Accepts:\n",
    "   - A `player_name` as part of the request body.\n",
    "   - Three uploaded image files (`selfie1`, `selfie2`, `selfie3`).\n",
    "2. Saves the uploaded selfies temporarily on disk.\n",
    "3. Calls `verification_system.verify_player_identity` with the player name and selfie paths.\n",
    "4. Cleans up (deletes) the temporary selfie files after verification.\n",
    "5. Returns a JSON response containing the verification result.\n",
    "\n",
    "**Error Handling:**\n",
    "- If any exception occurs during the process, returns a `500 Internal Server Error` with the exception message.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. GET `/verification_logs`\n",
    "\n",
    "**Endpoint to retrieve all saved verification logs.**\n",
    "\n",
    "### Workflow:\n",
    "1. Opens `verification_logs.json`.\n",
    "2. Loads the logs into memory.\n",
    "3. Returns the logs as a JSON response.\n",
    "\n",
    "**Error Handling:**\n",
    "- If the log file does not exist, returns an empty list `[]`.\n",
    "- If another exception occurs (e.g., reading error), returns a `500 Internal Server Error` with the error details.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415f34bf-05ac-481b-a4c0-e4602c4beb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.responses import JSONResponse\n",
    "from pydantic import BaseModel\n",
    "import tempfile\n",
    "import uuid\n",
    "\n",
    "app = FastAPI()\n",
    "verification_system = PlayerVerificationSystem()\n",
    "\n",
    "class VerificationRequest(BaseModel):\n",
    "    player_name: str\n",
    "\n",
    "@app.post(\"/verify_player\")\n",
    "async def verify_player(\n",
    "    request: VerificationRequest,\n",
    "    selfie1: UploadFile = File(...),\n",
    "    selfie2: UploadFile = File(...),\n",
    "    selfie3: UploadFile = File(...)\n",
    "):\n",
    "    try:\n",
    "        # Save uploaded selfies to temp files\n",
    "        temp_files = []\n",
    "        for i, selfie in enumerate([selfie1, selfie2, selfie3]):\n",
    "            temp_path = f\"{tempfile.gettempdir()}/{uuid.uuid4()}.jpg\"\n",
    "            with open(temp_path, \"wb\") as f:\n",
    "                f.write(await selfie.read())\n",
    "            temp_files.append(temp_path)\n",
    "        \n",
    "        # Perform verification\n",
    "        result = verification_system.verify_player_identity(\n",
    "            request.player_name,\n",
    "            temp_files,\n",
    "            save_log=True\n",
    "        )\n",
    "        \n",
    "        # Clean up temp files\n",
    "        for path in temp_files:\n",
    "            try:\n",
    "                os.remove(path)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return JSONResponse(content=result)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=f\"Verification failed: {str(e)}\"\n",
    "        )\n",
    "        \n",
    "\n",
    "@app.get(\"/verification_logs\")\n",
    "async def get_verification_logs():\n",
    "    try:\n",
    "        with open(\"verification_logs.json\", \"r\") as f:\n",
    "            logs = json.load(f)\n",
    "        return JSONResponse(content=logs)\n",
    "    except FileNotFoundError:\n",
    "        return JSONResponse(content=[])\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=f\"Failed to retrieve logs: {str(e)}\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
